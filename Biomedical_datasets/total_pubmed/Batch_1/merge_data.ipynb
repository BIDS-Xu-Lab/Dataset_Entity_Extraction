{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "import re\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import string\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['pmid', 'title', 'abstract', 'journal', 'pub_year', 'pub_month',\n",
      "       'authors', 'mesh_terms'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "new_data_ = joblib.load('/home/gy237/project/Biomedical_datasets/total_pubmed/New_PMID_abstract/abstracts_and_pubdata/abstracts_1253-1575_2.joblib')\n",
    "print(new_data_.columns)\n",
    "# old_data = joblib.load('/home/gy237/project/Biomedical_datasets/total_pubmed/New_PMID_abstract/abstracts_and_pubdata/abstracts_1253-1575.joblib')\n",
    "# print(old_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去重前： 5520745\n",
      "去重复后： 2888326\n"
     ]
    }
   ],
   "source": [
    "print('去重前：', len(new_data_))\n",
    "new_data = new_data_.drop_duplicates(subset=['pmid'], keep='last')\n",
    "print('去重复后：', len(new_data))\n",
    "\n",
    "# print('去重前：', len(old_data))\n",
    "# old_data = old_data.drop_duplicates(subset=['pmid'], keep='first')\n",
    "# print('去重复后：', len(old_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_data 2888326\n",
      "new_df 760405\n"
     ]
    }
   ],
   "source": [
    "# 以data作为keyword进行筛选abstract\n",
    "new_data = new_data[['pmid', 'abstract']]\n",
    "print('new_data',len(new_data))\n",
    "df = new_data[new_data['abstract'].str.contains(' data', case=False)]\n",
    "print('new_df', len(df))\n",
    "\n",
    "# old_data = old_data[['pmid', 'abstract']]\n",
    "# print('old_data',len(old_data))\n",
    "# old_data = old_data[old_data['abstract'].str.contains(' data', case=False)]\n",
    "# print('old_data', len(old_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace(folder_name):\n",
    "    file_list = os.listdir(folder_name)\n",
    "    file_list = [i.split('.')[0] for i in file_list]\n",
    "\n",
    "    filtered_df = new_data_[new_data_['pmid'].isin(file_list)]\n",
    "\n",
    "    dic = {'pmid':[], 'abstract':[]}\n",
    "    for pmid in file_list:\n",
    "        n_abstract = filtered_df[filtered_df['pmid'] == pmid]['abstract']\n",
    "        if len(n_abstract) > 0:\n",
    "            if pmid == '31804926':\n",
    "                for i in n_abstract:\n",
    "                    print(str(i))\n",
    "\n",
    "            n_abstract = n_abstract.iloc[-1]\n",
    "            n = split_abstracts(str(n_abstract))\n",
    "\n",
    "            with open(f'{folder_name}/{pmid}.txt', 'r') as file:\n",
    "                o = file.readlines()\n",
    "\n",
    "            if len(o) < len(n):\n",
    "                # print('Old', len(o))\n",
    "                # print('New', len(n))\n",
    "                dic['pmid'].append(pmid)\n",
    "                dic['abstract'].append(n_abstract)\n",
    "            if len(o) > len(n):\n",
    "                print(pmid)\n",
    "                print('Old', len(o))\n",
    "                print('New', len(n))\n",
    "\n",
    "    new_df = pd.DataFrame(dic)\n",
    "    print(len(new_df))\n",
    "    return new_df\n",
    "\n",
    "folder_name = '/home/gy237/project/Biomedical_datasets/total_pubmed/Batch_1/agreement'\n",
    "filtered_df = replace(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将abstracts分句并进行保存\n",
    "def ends_with_punctuation(text):\n",
    "    return text[-1] in string.punctuation if text else False\n",
    "\n",
    "def split_abstracts(abstract):\n",
    "    doc = nlp(abstract)\n",
    "    abstracts = [sent.text for sent in doc.sents]\n",
    "    assert len(abstracts) != 0\n",
    "        \n",
    "    new_abstracts = []\n",
    "    for j in abstracts:\n",
    "        j = j.strip().split('\\n')   # 有些内部会有\\n\n",
    "        for k in j:\n",
    "            if len(k.split(' ')) > 5 and ends_with_punctuation(k):\n",
    "                new_abstracts.append(k)\n",
    "    return new_abstracts\n",
    "\n",
    "def save_abstracts(data, name):\n",
    "    for index, row in data.iterrows():\n",
    "        pmid = row['pmid']\n",
    "        abstract = row['abstract']\n",
    "        doc = split_abstracts(abstract)\n",
    "        \n",
    "        # 以pmid为文件名创建txt文件\n",
    "        with open(f\"/home/gy237/project/Biomedical_datasets/total_pubmed/Batch_1/replace/{name}/{pmid}.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "            for j in doc:\n",
    "                file.write(j + '\\n')\n",
    "\n",
    "\n",
    "def replace(folder_name):\n",
    "    file_list = os.listdir(folder_name)\n",
    "    file_list = [i.split('.')[0] for i in file_list]\n",
    "\n",
    "    filtered_df = new_data_[new_data_['pmid'].isin(file_list)]\n",
    "\n",
    "    dic = {'pmid':[], 'abstract':[]}\n",
    "    for pmid in file_list:\n",
    "        n_abstract = filtered_df[filtered_df['pmid'] == pmid]['abstract']\n",
    "        if len(n_abstract) > 0:\n",
    "            # if pmid == '31804926':\n",
    "            #     for i in n_abstract:\n",
    "            #         print(str(i))\n",
    "\n",
    "            n_abstract = n_abstract.iloc[-1]\n",
    "            n = split_abstracts(str(n_abstract))\n",
    "\n",
    "            with open(f'{folder_name}/{pmid}.txt', 'r') as file:\n",
    "                o = file.readlines()\n",
    "\n",
    "            if len(o) != len(n):\n",
    "                # print('Old', len(o))\n",
    "                # print('New', len(n))\n",
    "                dic['pmid'].append(pmid)\n",
    "                dic['abstract'].append(n_abstract)\n",
    "            if len(o) > len(n):\n",
    "                print(pmid)\n",
    "                print('Old', len(o))\n",
    "                print('New', len(n))\n",
    "\n",
    "    new_df = pd.DataFrame(dic)\n",
    "    print(len(new_df))\n",
    "    return new_df\n",
    "\n",
    "    new_df = pd.DataFrame(dic)\n",
    "    print(len(new_df))\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "Gui = replace('/home/gy237/project/Biomedical_datasets/total_pubmed/Batch_1/Gui_collections')\n",
    "Kalpana = replace('/home/gy237/project/Biomedical_datasets/total_pubmed/Batch_1/Kalpana_collections')\n",
    "agreement = replace('/home/gy237/project/Biomedical_datasets/total_pubmed/Batch_1/agreement')\n",
    "\n",
    "save_abstracts(Gui, 'Gui_collections')\n",
    "save_abstracts(Kalpana, 'Kalpana_collections')\n",
    "save_abstracts(agreement, 'agreement')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['37591491.txt', '6346023.txt', '22515297.txt', '27016680.txt', '10657818.txt', '30705958.txt', '30895828.txt', '20809428.txt', '34066147.txt', '10713456.txt', '10194149.txt', '12616319.txt', '15778628.txt', '30910098.txt', '37490260.txt', '3000419.txt', '35161585.txt', '33172140.txt', '35356913.txt', '12556355.txt', '26042604.txt', '32152104.txt', '18829980.txt', '22011129.txt', '29035720.txt', '37491428.txt', '39165603.txt', '33569569.txt', '8214108.txt', '31804926.txt', '11169927.txt', '16164819.txt', '30459531.txt', '38228772.txt', '22935033.txt', '10084181.txt', '37590149.txt', '20407350.txt', '19861938.txt', '26142899.txt', '26693134.txt', '21406389.txt', '11308491.txt', '37526980.txt', '37029917.txt', '14871383.txt', '19371988.txt', '31987244.txt', '27042800.txt', '16834830.txt', '31682896.txt', '25689741.txt', '14711821.txt', '27399252.txt', '21903727.txt', '38374749.txt', '37881318.txt', '26190333.txt', '37548437.txt', '25954435.txt', '11932442.txt', '26541884.txt', '33969279.txt', '35783769.txt', '32903364.txt', '24121286.txt', '19781743.txt', '32620918.txt', '38681818.txt', '19269992.txt', '24022723.txt', '33183657.txt', '33804605.txt', '35419050.txt', '38146179.txt', '32227194.txt', '24770713.txt', '8125080.txt', '16298512.txt', '37684677.txt', '23361142.txt', '23574685.txt', '17348926.txt', '33560377.txt', '30042093.txt', '18476013.txt', '36441323.txt', '30072322.txt', '26106934.txt', '29152987.txt', '9358609.txt', '12071744.txt', '6260946.txt', '35886543.txt', '38560530.txt', '34237071.txt', '32123870.txt', '10751684.txt', '29983110.txt', '37002699.txt']\n",
      "39165603.txt\n",
      "37881318.txt\n",
      "38146179.txt\n",
      "30042093.txt\n",
      "35886543.txt\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "pmids = os.listdir('/home/gy237/project/Biomedical_datasets/total_pubmed/Batch_2/Batch_2')\n",
    "print(pmids)\n",
    "\n",
    "for pmid in pmids:\n",
    "    with open(f'/home/gy237/project/Biomedical_datasets/total_pubmed/Batch_2/Batch_2/{pmid}', 'r', encoding='utf-8') as f:\n",
    "        data_2 = f.readlines()\n",
    "    with open(f'/home/gy237/project/Biomedical_datasets/total_pubmed/Batch_1/Gui_collections/{pmid}', 'r', encoding='utf-8') as f:\n",
    "        data = f.readlines()\n",
    "\n",
    "    if len(data_2) != len(data):\n",
    "        print(pmid)\n",
    "        assert len(data_2) < len(data)\n",
    "        destination_folder = '/home/gy237/project/Biomedical_datasets/total_pubmed/Batch_2/replace'\n",
    "        # 执行复制操作\n",
    "        shutil.copy(f'/home/gy237/project/Biomedical_datasets/total_pubmed/Batch_1/Gui_collections/{pmid}', destination_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
