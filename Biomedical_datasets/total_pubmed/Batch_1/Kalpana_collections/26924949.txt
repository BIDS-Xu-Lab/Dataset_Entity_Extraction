This paper presents a 6-DOF Pose Estimation (PE) method for a Robotic Navigation Aid (RNA) for the visually impaired.
The RNA uses a single 3D camera for PE and object detection.
The proposed method processes the camera's intensity and range data to estimates the camera's egomotion that is then used by an Extended Kalman Filter (EKF) as the motion model to track a set of visual features for PE.
A RANSAC process is employed in the EKF to identify inliers from the visual feature correspondences between two image frames.
Only the inliers are used to update the EKF's state.
The EKF integrates the egomotion into the camera's pose in the world coordinate system.
To retain the EKF's consistency, the distance between the camera and the floor plane (extracted from the range data) is used by the EKF as the observation of the camera's z coordinate.
Experimental results demonstrate that the proposed method results in accurate pose estimates for positioning the RNA in indoor environments.
Based on the PE method, a wayfinding system is developed for localization of the RNA in a home environment.
The system uses the estimated pose and the floorplan to locate the RNA user in the home environment and announces the points of interest and navigational commands to the user through a speech interface.
This work was motivated by the limitations of the existing navigation technology for the visually impaired.
Most of the existing methods use a point/line measurement sensor for indoor object detection.
Therefore, they lack capability in detecting 3D objects and positioning a blind traveler.
Stereovision has been used in recent research.
However, it cannot provide reliable depth data for object detection.
Also, it tends to produce a lower localization accuracy because its depth measurement error quadratically increases with the true distance.
This paper suggests a new approach for navigating a blind traveler.
The method uses a single 3D time-of-flight camera for both 6-DOF PE and 3D object detection and thus results in a small-sized but powerful RNA.
Due to the camera's constant depth accuracy, the proposed egomotion estimation method results in a smaller error than that of existing methods.
A new EKF method is proposed to integrate the egomotion into the RNA's 6-DOF pose in the world coordinate system by tracking both visual and geometric features of the operating environment.
The proposed method substantially reduces the pose error of a standard EKF method and thus supports a longer range navigation task.
One limitation of the method is that it requires a feature-rich environment to work well.
